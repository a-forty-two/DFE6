{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloAPIs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZ84pnUQ9p0erhUdB/nRuS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/DFE6/blob/main/HelloAPIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1s_MwEw3GRV",
        "outputId": "b9cf22af-4a53-476d-c81c-1b3f3b979e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-cognitiveservices-vision-computervision in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.7/dist-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\n",
            "Requirement already satisfied: msrest>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from azure-cognitiveservices-vision-computervision) (0.6.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (0.6.1)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade azure-cognitiveservices-vision-computervision\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "id": "VTH6uQPF3N59"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subscription_key = \"7db033dbbbc141e1af52f567e4c9cc36\"\n",
        "endpoint = \"https://popopopopo.cognitiveservices.azure.com/\""
      ],
      "metadata": {
        "id": "jZNuM3tr3gh8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creds= CognitiveServicesCredentials(subscription_key)\n",
        "computervision_client = ComputerVisionClient(endpoint, creds)\n",
        "# API Authentication settings"
      ],
      "metadata": {
        "id": "R70IuGyQ4mus"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseimgurl = 'https://dodokilledplatypus.blob.core.windows.net/images/0000'\n",
        "allurls = []\n",
        "for i in range(3):\n",
        "  filename = baseimgurl + str(i+1) + '.jpeg'\n",
        "  allurls.append(filename)\n",
        "\n",
        "allurls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT3tDUFz4_c0",
        "outputId": "c53b6569-c14f-494f-8c43-1b52c6285057"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://dodokilledplatypus.blob.core.windows.net/images/00001.jpeg',\n",
              " 'https://dodokilledplatypus.blob.core.windows.net/images/00002.jpeg',\n",
              " 'https://dodokilledplatypus.blob.core.windows.net/images/00003.jpeg']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Describe an Image - remote\n",
        "This example describes the contents of an image with the confidence score.\n",
        "'''\n",
        "print(\"===== Describe an image - remote =====\")\n",
        "# Call API\n",
        "\n",
        "for url in allurls:\n",
        "  description_results = computervision_client.describe_image(url)\n",
        "  print(\"Description of remote image: \")\n",
        "  if (len(description_results.captions) == 0):\n",
        "      print(\"No description detected.\")\n",
        "  else:\n",
        "      for caption in description_results.captions:\n",
        "          print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
        "  print('**************************')\n",
        "\n",
        "# Get the captions (descriptions) from the response, with confidence level\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kabQiDln6zEI",
        "outputId": "72e0aa43-6f25-4cd1-9c45-75a775d82b35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Describe an image - remote =====\n",
            "Description of remote image: \n",
            "'a man and woman posing for a picture' with confidence 52.03%\n",
            "**************************\n",
            "Description of remote image: \n",
            "'shape' with confidence 50.39%\n",
            "**************************\n",
            "Description of remote image: \n",
            "'icon' with confidence 96.81%\n",
            "**************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Categorize an Image - remote\n",
        "This example extracts (general) categories from a remote image with a confidence score.\n",
        "'''\n",
        "print(\"===== Categorize an image - remote =====\")\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"categories\"]\n",
        "# Call API with URL and features\n",
        "\n",
        "for url in allurls:\n",
        "  categorize_results_remote = computervision_client.analyze_image(url , remote_image_features)\n",
        "  # Print results with confidence score\n",
        "  print(\"Categories from remote image: \")\n",
        "  if (len(categorize_results_remote.categories) == 0):\n",
        "      print(\"No categories detected.\")\n",
        "  else:\n",
        "      for category in categorize_results_remote.categories:\n",
        "          print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
        "  print('**********')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jmTfUHD7T-9",
        "outputId": "119488ac-0c1f-4451-a766-3c522013114e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Categorize an image - remote =====\n",
            "Categories from remote image: \n",
            "'people_' with confidence 79.30%\n",
            "**********\n",
            "Categories from remote image: \n",
            "'others_' with confidence 17.58%\n",
            "**********\n",
            "Categories from remote image: \n",
            "'text_sign' with confidence 14.84%\n",
            "**********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tag an Image - remote\n",
        "This example returns a tag (key word) for each thing in the image.\n",
        "'''\n",
        "print(\"===== Tag an image - remote =====\")\n",
        "# Call API with remote image\n",
        "for url in allurls:\n",
        "  tags_result_remote = computervision_client.tag_image(url )\n",
        "\n",
        "  # Print results with confidence score\n",
        "  print(\"Tags in the remote image: \")\n",
        "  if (len(tags_result_remote.tags) == 0):\n",
        "      print(\"No tags detected.\")\n",
        "  else:\n",
        "      for tag in tags_result_remote.tags:\n",
        "          print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
        "\n",
        "  print('*************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCifHuO97wE_",
        "outputId": "41205fc9-a3f0-488f-9b8d-780307211220"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Tag an image - remote =====\n",
            "Tags in the remote image: \n",
            "'clothing' with confidence 99.70%\n",
            "'person' with confidence 99.32%\n",
            "'human face' with confidence 98.41%\n",
            "'man' with confidence 94.85%\n",
            "'outdoor' with confidence 94.79%\n",
            "'smile' with confidence 92.92%\n",
            "'coat' with confidence 91.53%\n",
            "'text' with confidence 86.89%\n",
            "'jacket' with confidence 84.15%\n",
            "'suit' with confidence 72.94%\n",
            "'posing' with confidence 65.38%\n",
            "'standing' with confidence 63.36%\n",
            "'woman' with confidence 54.82%\n",
            "*************\n",
            "Tags in the remote image: \n",
            "'animated cartoon' with confidence 95.96%\n",
            "'animation' with confidence 94.13%\n",
            "'illustration' with confidence 93.42%\n",
            "'clipart' with confidence 90.92%\n",
            "'drawing' with confidence 88.07%\n",
            "'fiction' with confidence 85.87%\n",
            "'cartoon' with confidence 71.44%\n",
            "'anime' with confidence 69.29%\n",
            "'art' with confidence 68.25%\n",
            "*************\n",
            "Tags in the remote image: \n",
            "'symbol' with confidence 96.65%\n",
            "'logo' with confidence 95.66%\n",
            "'font' with confidence 93.46%\n",
            "'graphics' with confidence 90.83%\n",
            "'circle' with confidence 90.57%\n",
            "'trademark' with confidence 86.31%\n",
            "'screenshot' with confidence 84.16%\n",
            "'design' with confidence 52.69%\n",
            "*************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Detect Faces - remote\n",
        "This example detects faces in a remote image, gets their gender and age, \n",
        "and marks them with a bounding box.\n",
        "'''\n",
        "\n",
        "\n",
        "print(\"===== Detect Faces - remote =====\")\n",
        "# Get an image with faces\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"faces\"]\n",
        "# Call the API with remote URL and features\n",
        "\n",
        "for url in allurls:\n",
        "  detect_faces_results_remote = computervision_client.analyze_image(url, remote_image_features)\n",
        "\n",
        "  # Print the results with gender, age, and bounding box\n",
        "  print(\"Faces in the remote image: \")\n",
        "  if (len(detect_faces_results_remote.faces) == 0):\n",
        "      print(\"No faces detected.\")\n",
        "  else:\n",
        "      for face in detect_faces_results_remote.faces:\n",
        "          print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
        "          face.face_rectangle.left, face.face_rectangle.top, \\\n",
        "          face.face_rectangle.left + face.face_rectangle.width, \\\n",
        "          face.face_rectangle.top + face.face_rectangle.height))\n",
        "  print('***********')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leqHPyx07-Rt",
        "outputId": "9f784cfd-d9c8-4bd1-dc45-476803777170"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Detect Faces - remote =====\n",
            "Faces in the remote image: \n",
            "'Male' of age 35 at location 159, 37, 200, 78\n",
            "***********\n",
            "Faces in the remote image: \n",
            "No faces detected.\n",
            "***********\n",
            "Faces in the remote image: \n",
            "No faces detected.\n",
            "***********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H6LcgheB9V2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}